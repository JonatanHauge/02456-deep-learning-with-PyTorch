{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZW0gaQO81Sq"
   },
   "source": [
    "# CNN on CIFAR-10\n",
    "\n",
    "In this notebook you need to put what you have learned into practice, and create your own convolutional classifier for the CIFAR-10 dataset.\n",
    "\n",
    "The images in CIFAR-10 are RGB images (3 channels) with size 32x32 (so they have size 3x32x32). There are 10 different classes. See examples below.\n",
    "\n",
    "![cifar10](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/cifar10.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htyg7xxN81St"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3009,
     "status": "ok",
     "timestamp": 1662640064042,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "v3u2GIWr81Su"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn import metrics\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "def accuracy(target, pred):\n",
    "    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())\n",
    "\n",
    "def compute_confusion_matrix(target, pred, normalize=None):\n",
    "    return metrics.confusion_matrix(\n",
    "        target.detach().cpu().numpy(), \n",
    "        pred.detach().cpu().numpy(),\n",
    "        normalize=normalize\n",
    "    )\n",
    "\n",
    "def show_image(img):\n",
    "    img = img.detach().cpu()\n",
    "    img = img / 2 + 0.5   # unnormalize\n",
    "    with sns.axes_style(\"white\"):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img.permute((1, 2, 0)).numpy())\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "referenced_widgets": [
      "2435970902984fb09c0a257131d742be",
      "548c47f6e8fa4a37a939535ef670020c",
      "9d6456ca327f4a858e92c13cd417340d",
      "67bbc7b98abf41f1927a7362aff86fe7",
      "b589c04a1dab4fd6a9c5cdd4c99d6cf9",
      "7289f6e93f2e44819780bb1b7918876b",
      "39e70cbbd65d4541a04c23c069b001ed",
      "0c6f066e4b44478a89c7384f6c284ece",
      "aa44e013a906441892f252576e269634",
      "07174f985c5b480b84ff77f61dd88f97",
      "30ae8a12c6a54ffcb37973b9ca01a07c"
     ]
    },
    "executionInfo": {
     "elapsed": 18641,
     "status": "ok",
     "timestamp": 1662640112137,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "QZeTujLC81S3",
    "outputId": "a75010e0-f99a-4ce5-eb6a-2df4f6150777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# The output of torchvision datasets are PIL images in the range [0, 1]. \n",
    "# We transform them to PyTorch tensors and rescale them to be in the range [-1, 1].\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # subtract 0.5 and divide by 0.5\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 64  # both for training and testing\n",
    "\n",
    "# Load datasets\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
    "\n",
    "# Map from class index to class name.\n",
    "classes = {index: name for name, index in train_set.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1662640116989,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "JDHkc52L81S9",
    "outputId": "2fe8610c-37c6-47c8-99e1-092299c6050f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "Number of points: 50000\n",
      "Batch dimension (B x C x H x W): torch.Size([64, 3, 32, 32])\n",
      "Number of distinct labels: 10 (unique labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})\n",
      "\n",
      "Test data\n",
      "Number of points: 10000\n",
      "Batch dimension (B x C x H x W): torch.Size([64, 3, 32, 32])\n",
      "Number of distinct labels: 10 (unique labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data\")\n",
    "print(\"Number of points:\", len(train_set))\n",
    "x, y = next(iter(train_loader))\n",
    "print(\"Batch dimension (B x C x H x W):\", x.shape)\n",
    "print(f\"Number of distinct labels: {len(set(train_set.targets))} (unique labels: {set(train_set.targets)})\")\n",
    "\n",
    "print(\"\\nTest data\")\n",
    "print(\"Number of points:\", len(test_set))\n",
    "x, y = next(iter(test_loader))\n",
    "print(\"Batch dimension (B x C x H x W):\", x.shape)\n",
    "print(f\"Number of distinct labels: {len(set(test_set.targets))} (unique labels: {set(test_set.targets)})\")\n",
    "\n",
    "n_classes = len(set(test_set.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSA1h94681TB"
   },
   "source": [
    "### Show example images\n",
    "\n",
    "Run multiple times to see different examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 2498,
     "status": "ok",
     "timestamp": 1662640125654,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "njJy0klP81TD",
    "outputId": "decc1858-fd68-4969-8aca-b9194276967b"
   },
   "outputs": [],
   "source": [
    "# Get random training images and show them.\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "show_image(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt3BVFMF81TI"
   },
   "source": [
    "## Define a convolutional neural network\n",
    "\n",
    "\n",
    "**Assignment 1:** Define a convolutional neural network. \n",
    "You may use the code from previous notebooks.\n",
    "We suggest that you start with a small network, and make sure that everything is working.\n",
    "Once you can train successfully, come back and improve the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1662640362237,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "_EsKbw3o81TK",
    "outputId": "9ea47766-bca0-488e-8166-319efc4506b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Flatten(start_dim=1, end_dim=-1)\n",
      "    (5): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (6): Dropout(p=0.4, inplace=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (9): Dropout(p=0.4, inplace=False)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PrintSize(nn.Module):\n",
    "    \"\"\"Utility module to print current shape of a Tensor in Sequential, only at the first pass.\"\"\"\n",
    "    \n",
    "    first = True\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.first:\n",
    "            print(f\"Size: {x.size()}\")\n",
    "            self.first = False\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # Your code here!\n",
    "        activation_fn = nn.ReLU\n",
    "        \n",
    "        self.net = nn.Sequential(                         #In size: (3, 32, 32)\n",
    "            nn.Conv2d(3, 32, 5, stride = 1, padding = 2), #Out: (32, 32, 32)\n",
    "            nn.MaxPool2d(2),                              #Out: (32, 16, 16)\n",
    "            nn.Conv2d(32, 32, 3, stride = 1, padding = 1),#Out: (32, 16, 16)\n",
    "            nn.MaxPool2d(2),                              #Out: (32, 8, 8)\n",
    "            nn.Flatten(),                                 #Out: (1, 32*8*8)\n",
    "            nn.Linear(32*8*8, 256),\n",
    "            nn.Dropout(p=0.4, inplace = False),\n",
    "            activation_fn(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.Dropout(p=0.4, inplace = False),\n",
    "            activation_fn(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Your code here!\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "model = Model(n_classes)\n",
    "device = torch.device('cpu')  # use cuda or cpu\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-IUg3sq81TQ"
   },
   "source": [
    "## Define a loss function and optimizer\n",
    "\n",
    "**Assignment 2:** Define the loss function and optimizer.\n",
    "You might need to experiment a bit with the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1662640370072,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "48AX85QP81TR"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  # Your code here!\n",
    "optimizer1 = optim.Adam(model.parameters(), lr=2e-3, weight_decay = 1e-4)  # Your code here!\n",
    "optimizer2 = optim.Adam(model.parameters(), lr=1e-3, weight_decay = 1e-4)\n",
    "optimizer3 = optim.Adam(model.parameters(), lr=1e-4, weight_decay = 1e-5)\n",
    "optimizer4 = optim.Adam(model.parameters(), lr=1e-5, weight_decay = 1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WneIN7C81TV"
   },
   "source": [
    "## Train the network\n",
    "\n",
    "**Assignment 3:** Finish the training loop below. \n",
    "Start by using a small number of epochs (e.g. 2).\n",
    "Even with a low number of epochs you should be able to see results that are better than chance.\n",
    "When everything is working increase the number of epochs to find out how good your network really is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iWT0ULctWvm1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 10])\n",
      "Output logits:\n",
      "[[-0.16913249 -0.02033221  0.14445566  0.21105538 -0.02100294 -0.00643574\n",
      "   0.1255863   0.10992227 -0.065941   -0.01032515]\n",
      " [-0.00900644 -0.0369533   0.0437164   0.19897887  0.15770139  0.2048621\n",
      "  -0.03750548  0.0255891  -0.11298218  0.11290933]]\n",
      "Output probabilities:\n",
      "[[0.08147892 0.0945515  0.11148973 0.11916775 0.0944881  0.09587459\n",
      "  0.10940571 0.10770533 0.09033598 0.09550243]\n",
      " [0.09332144 0.09074951 0.09837363 0.11489691 0.11025079 0.11557486\n",
      "  0.09069941 0.09660644 0.08410569 0.1054214 ]]\n"
     ]
    }
   ],
   "source": [
    "# Test the forward pass with dummy data\n",
    "out = model(torch.randn(2, 3, 32, 32, device=device))\n",
    "print(\"Output shape:\", out.size())\n",
    "print(f\"Output logits:\\n{out.detach().cpu().numpy()}\")\n",
    "print(f\"Output probabilities:\\n{out.softmax(1).detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NkUanRRb81TW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500     training accuracy: 0.70240625\n",
      "             test accuracy: 0.6895\n",
      "Step 1000    training accuracy: 0.7057769495412844\n",
      "             test accuracy: 0.6888\n",
      "Step 1500    training accuracy: 0.6948125\n",
      "             test accuracy: 0.6862\n",
      "Step 2000    training accuracy: 0.7185708142201835\n",
      "             test accuracy: 0.6817\n",
      "Step 2500    training accuracy: 0.7563920454545454\n",
      "             test accuracy: 0.7071\n",
      "Step 3000    training accuracy: 0.75896875\n",
      "             test accuracy: 0.7172\n",
      "Step 3500    training accuracy: 0.7898185483870968\n",
      "             test accuracy: 0.7191\n",
      "Step 4000    training accuracy: 0.8217013888888889\n",
      "             test accuracy: 0.7258\n",
      "Step 4500    training accuracy: 0.8276875\n",
      "             test accuracy: 0.7299\n",
      "Step 5000    training accuracy: 0.838372564935065\n",
      "             test accuracy: 0.7339\n",
      "Step 5500    training accuracy: 0.8497596153846154\n",
      "             test accuracy: 0.7347\n",
      "Step 6000    training accuracy: 0.84846875\n",
      "             test accuracy: 0.7332\n",
      "Step 6500    training accuracy: 0.8540599385245902\n",
      "             test accuracy: 0.7334\n",
      "Step 7000    training accuracy: 0.85096875\n",
      "             test accuracy: 0.7343\n",
      "Step 7500    training accuracy: 0.8477408008658008\n",
      "             test accuracy: 0.7333\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "validation_every_steps = 500\n",
    "\n",
    "step = 0\n",
    "model.train()\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "        \n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    optimizer = optimizer1\n",
    "    if epoch >= 3:\n",
    "        optimizer = optimizer2\n",
    "    if epoch >= 5:\n",
    "        optimizer = optimizer3\n",
    "    if epoch >= 7:\n",
    "        optimizer = optimizer4\n",
    "    \n",
    "    train_accuracies_batches = []\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass, compute gradients, perform one training step.\n",
    "        # Your code here!\n",
    "        # Forward pass.\n",
    "        output = model(inputs)\n",
    "        \n",
    "        # Compute loss.\n",
    "        loss = loss_fn(output, targets)\n",
    "        \n",
    "        # Clean up gradients from the model.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients based on the loss from the current batch (backpropagation).\n",
    "        loss.backward()\n",
    "        \n",
    "        # Take one optimizer step using the gradients computed in the previous step.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Increment step counter\n",
    "        step += 1\n",
    "        \n",
    "        # Compute accuracy.\n",
    "        predictions = output.max(1)[1]\n",
    "        train_accuracies_batches.append(accuracy(targets, predictions))\n",
    "        \n",
    "        if step % validation_every_steps == 0:\n",
    "            \n",
    "            # Append average training accuracy to list.\n",
    "            train_accuracies.append(np.mean(train_accuracies_batches))\n",
    "            \n",
    "            train_accuracies_batches = []\n",
    "        \n",
    "            # Compute accuracies on validation set.\n",
    "            valid_accuracies_batches = []\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for inputs, targets in test_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    output = model(inputs)\n",
    "                    loss = loss_fn(output, targets)\n",
    "\n",
    "                    predictions = output.max(1)[1]\n",
    "\n",
    "                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
    "                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))\n",
    "\n",
    "                model.train()\n",
    "                \n",
    "            # Append average validation accuracy to list.\n",
    "            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))\n",
    "     \n",
    "            print(f\"Step {step:<5}   training accuracy: {train_accuracies[-1]}\")\n",
    "            print(f\"             test accuracy: {valid_accuracies[-1]}\")\n",
    "\n",
    "print(\"Finished training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qAsbC8I81Ta"
   },
   "source": [
    "## Test the network\n",
    "\n",
    "Now we show a batch of test images and generate a table below with the true and predicted class for each of these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LT0RoAC81Tc"
   },
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(test_loader))\n",
    "inputs, targets = inputs.to(device), targets.to(device)\n",
    "show_image(make_grid(inputs))\n",
    "plt.show()\n",
    "\n",
    "outputs = model(inputs)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print(\"    TRUE        PREDICTED\")\n",
    "print(\"-----------------------------\")\n",
    "for target, pred in zip(targets, predicted):\n",
    "    print(f\"{classes[target.item()]:^13} {classes[pred.item()]:^13}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISA6LJJO81Tg"
   },
   "source": [
    "We now evaluate the network as above, but on the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Smv6_BwF81Ti"
   },
   "outputs": [],
   "source": [
    "# Evaluate test set\n",
    "confusion_matrix = np.zeros((n_classes, n_classes))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_accuracies = []\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        predictions = output.max(1)[1]\n",
    "\n",
    "        # Multiply by len(inputs) because the final batch of DataLoader may be smaller (drop_last=True).\n",
    "        test_accuracies.append(accuracy(targets, predictions) * len(inputs))\n",
    "        \n",
    "        confusion_matrix += compute_confusion_matrix(targets, predictions)\n",
    "\n",
    "    test_accuracy = np.sum(test_accuracies) / len(test_set)\n",
    "    \n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylxBAyXwI7Ab"
   },
   "source": [
    "Here we report the **average test accuracy** (number of correct predictions divided by test set size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "a5-c_CDAI7Ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.734\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMfUqY9rI7Ab"
   },
   "source": [
    "Here we look a bit more in depth into the performance of the classifier, using the **confusion matrix**. The entry at the i-th row and j-th column indicates the number of samples with true label being the i-th class and predicted label being the j-th class.\n",
    "\n",
    "We normalize the rows: given all examples of a specific class (row), we can observe here how they are classified by our model. Ideally, we would like the entries on the diagonals to be 1, and everything else 0. This would mean that all examples from that class are classified correctly.\n",
    "\n",
    "The classes that are harder to classify for our model have lower numbers on the diagonal. We can then see exactly *how* they are misclassified by looking at the rest of the row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShcEZDExI7Ab"
   },
   "outputs": [],
   "source": [
    "def normalize(matrix, axis):\n",
    "    axis = {'true': 1, 'pred': 0}[axis]\n",
    "    return matrix / matrix.sum(axis=axis, keepdims=True)\n",
    "\n",
    "x_labels = [classes[i] for i in classes]\n",
    "y_labels = x_labels\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(\n",
    "    ax=plt.gca(),\n",
    "    data=normalize(confusion_matrix, 'true'),\n",
    "    annot=True,\n",
    "    linewidths=0.5,\n",
    "    cmap=\"Reds\",\n",
    "    cbar=False,\n",
    "    fmt=\".2f\",\n",
    "    xticklabels=x_labels,\n",
    "    yticklabels=y_labels,\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.ylabel(\"True class\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw13Y86VI7Ac"
   },
   "source": [
    "Here we focus on the diagonal and plot the numbers in a bar plot. This gives us a clearer picture of the accuracy of the model for different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xv75wMhVI7Ac"
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('whitegrid'):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(x=x_labels, y=np.diag(normalize(confusion_matrix, 'true')))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Per-class accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocnQOBAl81Tn"
   },
   "source": [
    "**Assignment 4:** \n",
    "1. Go back and improve performance of the network. By using enough convolutional layers with enough channels (and by training for long enough), you should easily be able to get a test accuracy above 60%, but see how much further you can get it! Can you reach 70%?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "CNN, 1 conv layer with 16 channels 5x5 kernel, 1 2x2 max pool layer, 2 x linear layer 128 neurons: 61.4 %\n",
    "\n",
    "CNN, conv 32 C 5x5 kernel, 2x2 max pool, conv 32 channels 3x3 kernel, 2x2 max pool, 256 neurons, dropout 0.3, 64 neurons, dropout 0.3: 65.4 % \n",
    "\n",
    "Same as above, but with weight_decay = 1e-5: 68.3 %\n",
    "\n",
    "Same as above, but with weight_decay = 1e-4: 70.4 %\n",
    "\n",
    "Same as above, but with weight_decay = 1e-3: 71.1 %\n",
    "\n",
    "Same as above, but with weight_decay = 2e-3: 68.7 %\n",
    "\n",
    "Same as above, but with weight_decay = 1e-2: 62.5 %\n",
    "\n",
    "All the following networks is trained with weight_decay = 1e-3.\n",
    "\n",
    "CNN, conv 32 C 5x5 kernel, 2x2 max pool, batchnorm, conv 32 channels 3x3 kernel, 2x2 max pool, batchnorm, 256 neurons, dropout 0.3, 64 neurons, dropout 0.3: 62.0 % \n",
    "\n",
    "CNN, conv 32 C 5x5 kernel, 2x2 max pool, bathcnorm, conv 32 channels 3x3 kernel, 2x2 max pool, 256 neurons, dropout 0.3, 64 neurons, dropout 0.3: 64.8 % \n",
    "\n",
    "CNN, conv 64 C 5x5 kernel, 2x2 max pool, conv 64 channels 3x3 kernel, 2x2 max pool, 256 neurons, dropout 0.3, 64 neurons, dropout 0.3: 64.1 % \n",
    "\n",
    "CNN, conv 64 C 5x5 kernel, 2x2 max pool, conv 64 channels 3x3 kernel, 2x2 max pool, 512 neurons, dropout 0.3, 128 neurons, dropout 0.3: 64.0 % \n",
    "\n",
    "#### Best results:\n",
    "\n",
    "CNN, conv 32 C 5x5 kernel, 2x2 max pool, conv 32 channels 3x3 kernel, 2x2 max pool, 256 neurons, dropout 0.3, 64 neurons, dropout 0.3, changing the learning rate as a function of epochs, training for 8 epochs: 74.9 % accuracy\n",
    "\n",
    "CNN, conv 32 C 5x5 kernel, 2x2 max pool, conv 32 channels 3x3 kernel, 2x2 max pool, 256 neurons, dropout 0.4, 64 neurons, dropout 0.4, changing the learning rate as a function of epochs, training for 8 epochs: 74.5 % accuracy\n",
    "\n",
    "\n",
    "2. Briefly describe what you did and any experiments you did along the way as well as what results you obtained.\n",
    "Did anything surprise you during the exercise?\n",
    "What were the changes that seemed to improve performance the most?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "I tried changing the architechture and the hyperparameters. I changed the number of conv. layers, the size of them, the size of the kernels, the size of the hidden linear layers, the dropout parameter, batchnormalization. I also tried changing the weight decay in the Adam optimizer and implemented an optimizer that changes as a function of epochs.\n",
    "\n",
    "Weight-decay in Adam helped a lot, the convolutional layers plus max pool also helped a lot and implementing a changing optimizer!\n",
    "\n",
    "3. Write down key lessons/insights you got during this exercise.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "It is important to keep track of the different trial to see what works and what does not work.\n",
    "\n",
    "There is a high degree of uncertainty due to the random initialization of weights!\n",
    "\n",
    "Tunning of parameters is really important!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Nzefavy81To"
   },
   "source": [
    "# Training on GPU\n",
    "\n",
    "**Optional Assignment:**\n",
    "If you have a GPU, we suggest that you try training your model on GPU. For this, you need to move the model to GPU after defining it, which will recursively go over all modules and convert their parameters and buffers to CUDA tensors. You also need to transfer both the inputs and targets to GPU at each training step, before performing the forward pass.\n",
    "\n",
    "The code for this is already in place: notice the `.to(device)` statements. The only thing left to do is change the definition of `device` from `'cpu'` to `'cuda'`.\n",
    "\n",
    "If you don't have a GPU, you can do this on [Google Colab](https://research.google.com/colaboratory/).\n",
    "\n",
    "Use the code below to check if any GPU is avaiable in your current setup. This should print the models of all available GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I09rtehbaCRH"
   },
   "outputs": [],
   "source": [
    "# Check if we have GPUs available\n",
    "print(\"Available CUDA devices:\", [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "actFGqQZM9Vd"
   },
   "source": [
    "You may not notice any significant speed-up from using a GPU. This is probably because your network is really small. Try increasing the width of your network (number of channels in the convolutional layers) and see if you observe any speed-up on GPU compared to CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8mEIylU81Tp"
   },
   "source": [
    "# Exercise from Michael Nielsen's book\n",
    "\n",
    "**Assignment 5:** Pick an exercise of your own choice from [Michael Nielsen's book](http://neuralnetworksanddeeplearning.com/).\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Verify that σ′(z)=σ(z)(1−σ(z))\n",
    "\n",
    "We remember that $\\sigma(z) =  \\frac{1}{1 + e^{-z}} = \\frac{e^z}{1 + e^{z}}$\n",
    "\n",
    "Therefore, $\\sigma'(z) = \\frac{-1\\cdot -e^{-z}}{(1+e^{-z})^2} = \\frac{1}{1+e^{-z}}\\frac{e^{-z}}{1+e^{-z}} = \n",
    " \\sigma(z)\\cdot \\frac{e^{-z}+1-1}{1+e^{-z}} = \\sigma(z)\\cdot (\\frac{e^{-z}+1}{1+e^{-z}} - \\frac{1}{1+e^{-z}}) = \n",
    " \\sigma(z)\\cdot (1 - \\frac{1}{1+e^{-z}}) = \\sigma(z)\\cdot (1 - \\sigma(z))$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qh7KTAdWD_zx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07174f985c5b480b84ff77f61dd88f97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c6f066e4b44478a89c7384f6c284ece": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2435970902984fb09c0a257131d742be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_548c47f6e8fa4a37a939535ef670020c",
       "IPY_MODEL_9d6456ca327f4a858e92c13cd417340d",
       "IPY_MODEL_67bbc7b98abf41f1927a7362aff86fe7"
      ],
      "layout": "IPY_MODEL_b589c04a1dab4fd6a9c5cdd4c99d6cf9"
     }
    },
    "30ae8a12c6a54ffcb37973b9ca01a07c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39e70cbbd65d4541a04c23c069b001ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "548c47f6e8fa4a37a939535ef670020c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7289f6e93f2e44819780bb1b7918876b",
      "placeholder": "​",
      "style": "IPY_MODEL_39e70cbbd65d4541a04c23c069b001ed",
      "value": "100%"
     }
    },
    "67bbc7b98abf41f1927a7362aff86fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07174f985c5b480b84ff77f61dd88f97",
      "placeholder": "​",
      "style": "IPY_MODEL_30ae8a12c6a54ffcb37973b9ca01a07c",
      "value": " 170498071/170498071 [00:13&lt;00:00, 13829808.62it/s]"
     }
    },
    "7289f6e93f2e44819780bb1b7918876b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d6456ca327f4a858e92c13cd417340d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c6f066e4b44478a89c7384f6c284ece",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa44e013a906441892f252576e269634",
      "value": 170498071
     }
    },
    "aa44e013a906441892f252576e269634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b589c04a1dab4fd6a9c5cdd4c99d6cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
